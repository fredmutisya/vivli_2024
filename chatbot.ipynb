{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4274a-5c5f-497e-995d-14c6e7f5a05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d73cb3b-e35b-41f8-89e9-75bf13534885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d70db7-053c-423f-81a9-c6b9dd0f485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\vivli_2024\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating report: 'OpenAI' object has no attribute 'chat_completions'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.docstore.document import Document\n",
    "from openai import OpenAI  # Import the synchronous OpenAI client\n",
    "import openai\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the local file store for caching\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "# Initialize the OpenAI embedding model\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "embedder = OpenAIEmbeddings(api_key=openai_api_key)\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "csv_path = 'abstracts_output.csv'  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Step 2: Prepare documents and metadata\n",
    "texts = df['text'].tolist()\n",
    "metadata = [{\"authors\": row['authors'], \"title\": row['title'], \"source\": row['source'], \"year\": row['year']} for _, row in df.iterrows()]\n",
    "\n",
    "# Convert each text and its metadata into a Document object\n",
    "documents = [Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadata)]\n",
    "\n",
    "# Step 3: Create the FAISS vector store from the documents and cache-backed embedder\n",
    "vector_store = FAISS.from_documents(documents, embedder)\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Step 4: Use the vector store to retrieve the top 5 relevant documents\n",
    "query = \"Summarize the most relevant abstracts\"  # Replace this with your actual query\n",
    "top_k_documents = vector_store.similarity_search(query, k=2)\n",
    "\n",
    "# Step 5: Generate the report using RAG\n",
    "\n",
    "def generate_report(client, top_k_documents):\n",
    "    final_report = \"### AI Summary of Surveillance Data\\n\"\n",
    "    references = []\n",
    "\n",
    "    try:\n",
    "        # Iterate through the retrieved documents\n",
    "        for doc in top_k_documents:\n",
    "            text = doc.page_content\n",
    "            meta = doc.metadata\n",
    "\n",
    "            # Prepare the prompt for summarization\n",
    "            summary_prompt = \"You are helping doctors use research to determine if the antibiotic is appropriate for the infection, summarize the following text in a concise paragraph form, ensuring that all sentences are complete and properly structured:\"\n",
    "            summary_response = client.chat_completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": f\"{summary_prompt}\\n{text}\"}],\n",
    "                max_tokens=100,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            summary_result = summary_response.choices[0].message.content.strip()\n",
    "\n",
    "            # Ensure the summary ends with a complete sentence by avoiding any dangling punctuation\n",
    "            summary_result = re.sub(r'\\.\\s*$', '', summary_result)\n",
    "\n",
    "            # Extract metadata for APA citation\n",
    "            authors = meta['authors'].split(\", \")\n",
    "            year = meta['year']\n",
    "            title = meta.get('title', 'Untitled')\n",
    "            source = meta.get('source', '')\n",
    "\n",
    "            if len(authors) == 1:\n",
    "                citation_in_text = f\"({authors[0]}, {year})\"\n",
    "            elif len(authors) == 2:\n",
    "                citation_in_text = f\"({authors[0]} & {authors[1]}, {year})\"\n",
    "            else:  # Three or more authors\n",
    "                citation_in_text = f\"({authors[0]} et al., {year})\"\n",
    "\n",
    "            # Format the full reference in APA style with the title included\n",
    "            if len(authors) == 1:\n",
    "                citation_full = f\"{authors[0]}. ({year}). {title}. {source}.\"\n",
    "            elif len(authors) == 2:\n",
    "                citation_full = f\"{authors[0]} & {authors[1]}. ({year}). {title}. {source}.\"\n",
    "            else:\n",
    "                citation_full = f\"{authors[0]}, {authors[1]}, & {authors[2]}. ({year}). {title}. {source}.\"\n",
    "\n",
    "            # Add the full reference to the references list\n",
    "            references.append(citation_full)\n",
    "\n",
    "            # Combine the summary and the APA citation, and put a full stop after the citation\n",
    "            paragraph = f\"{summary_result} {citation_in_text}.\"\n",
    "\n",
    "            # Append this paragraph to the final report\n",
    "            final_report += paragraph + \"\\n\\n\"\n",
    "\n",
    "        # Add the references section to the final report\n",
    "        final_report += \"\\n\\n### References\\n\"\n",
    "        for ref in references:\n",
    "            final_report += f\"{ref}\\n\\n\"\n",
    "\n",
    "        return final_report\n",
    "    except Exception as e:\n",
    "        return f\"Error generating report: {e}\"\n",
    "\n",
    "# Generate the report\n",
    "final_report = generate_report(client, top_k_documents)\n",
    "\n",
    "# Display the generated report\n",
    "print(final_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e933e3-521c-4b0d-ba48-596d315c3f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914cc163-867b-4095-a1ba-407c1c1b2984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927873a-42a8-4651-9a92-d7e12c5fd158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4fdcc2-aea4-448f-8e06-2cf7ca70f2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### AI Summary of Surveillance Data\n",
      "The study aimed to identify predictive factors for antimicrobial resistance and develop a treatment algorithm for afebrile outpatients with complicated cystitis. A retrospective study was conducted on 2,891 outpatients diagnosed with afebrile complicated cystitis from 2012 to 2018. The study used univariate analyses and multivariable regression models to predict resistance to various antibiotics. The results showed that the overall prevalence of resistance for the antibiotics ranged from 6.9% to 25 (Cooley LF et al., 2020).\n",
      "\n",
      "The study suggests that repurposing FDA-approved compounds could be the quickest way to reduce the impact of diseases caused by flaviviruses. Three fluoroquinolones, enoxacin, difloxacin, and ciprofloxacin, were found to limit the replication of flaviviruses such as Zika, dengue, Langat, and Modoc in HEK-293 cells. Enoxacin was found to suppress Zika virus replication at an intermediate stage, while cipro (Scroggs SLP et al., 2020).\n",
      "\n",
      "\n",
      "\n",
      "### References\n",
      "Cooley LF, Cohen JE, & Chen L. (2020). Algorithms to Enhance Empiric Antimicrobial Choice for Outpatients With Afebrile Complicated Cystitis Reflects Importance of Status of the Urinary Tract and Patient Place of Residence.. Urology. 2020 Nov;145:127-133. doi: 10.1016/j.urology.2020.08.036. Epub 2020 Sep 1..\n",
      "\n",
      "Scroggs SLP, Andrade CC, & Chinnasamy R. (2020). Old Drugs with New Tricks: Efficacy of Fluoroquinolones to Suppress Replication of Flaviviruses.. Viruses. 2020 Sep 13;12(9):1022. doi: 10.3390/v12091022..\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.docstore.document import Document\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI embedding model\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "embedder = OpenAIEmbeddings(api_key=openai_api_key)\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "csv_path = 'abstracts_output.csv'  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Step 2: Prepare documents and metadata\n",
    "texts = df['text'].tolist()\n",
    "metadata = [{\"authors\": row['authors'], \"title\": row['title'], \"source\": row['source'], \"year\": row['year']} for _, row in df.iterrows()]\n",
    "\n",
    "# Convert each text and its metadata into a Document object\n",
    "documents = [Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadata)]\n",
    "\n",
    "# Step 3: Create the FAISS vector store from the documents and cache-backed embedder\n",
    "vector_store = FAISS.from_documents(documents, embedder)\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Step 4: Use the vector store to retrieve the top 5 relevant documents\n",
    "query = \"Summarize the most relevant abstracts\"  # Replace this with your actual query\n",
    "top_k_documents = vector_store.similarity_search(query, k=2)\n",
    "\n",
    "# Step 5: Generate the report using RAG\n",
    "\n",
    "def generate_report(client, top_k_documents):\n",
    "    final_report = \"### AI Summary of Surveillance Data\\n\"\n",
    "    references = []\n",
    "\n",
    "    try:\n",
    "        # Iterate through the retrieved documents\n",
    "        for doc in top_k_documents:\n",
    "            text = doc.page_content\n",
    "            meta = doc.metadata\n",
    "\n",
    "            # Prepare the prompt for summarization\n",
    "            summary_prompt = \"You are helping doctors use research to determine if the antibiotic is appropriate for the infection. Summarize the following text in a concise paragraph form, ensuring that all sentences are complete and properly structured:\"\n",
    "            \n",
    "            # Use the new OpenAI client API call\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": f\"{summary_prompt}\\n{text}\"}],\n",
    "                model=\"gpt-4\",  # You can use \"gpt-4\" or \"gpt-3.5-turbo\"\n",
    "                max_tokens=100,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            # Access the result via the attribute\n",
    "            summary_result = chat_completion.choices[0].message.content.strip()\n",
    "\n",
    "            # Ensure the summary ends with a complete sentence by avoiding any dangling punctuation\n",
    "            summary_result = re.sub(r'\\.\\s*$', '', summary_result)\n",
    "\n",
    "            # Extract metadata for APA citation\n",
    "            authors = meta['authors'].split(\", \")\n",
    "            year = meta['year']\n",
    "            title = meta.get('title', 'Untitled')\n",
    "            source = meta.get('source', '')\n",
    "\n",
    "            if len(authors) == 1:\n",
    "                citation_in_text = f\"({authors[0]}, {year})\"\n",
    "            elif len(authors) == 2:\n",
    "                citation_in_text = f\"({authors[0]} & {authors[1]}, {year})\"\n",
    "            else:  # Three or more authors\n",
    "                citation_in_text = f\"({authors[0]} et al., {year})\"\n",
    "\n",
    "            # Format the full reference in APA style with the title included\n",
    "            if len(authors) == 1:\n",
    "                citation_full = f\"{authors[0]}. ({year}). {title}. {source}.\"\n",
    "            elif len(authors) == 2:\n",
    "                citation_full = f\"{authors[0]} & {authors[1]}. ({year}). {title}. {source}.\"\n",
    "            else:\n",
    "                citation_full = f\"{authors[0]}, {authors[1]}, & {authors[2]}. ({year}). {title}. {source}.\"\n",
    "\n",
    "            # Add the full reference to the references list\n",
    "            references.append(citation_full)\n",
    "\n",
    "            # Combine the summary and the APA citation, and put a full stop after the citation\n",
    "            paragraph = f\"{summary_result} {citation_in_text}.\"\n",
    "\n",
    "            # Append this paragraph to the final report\n",
    "            final_report += paragraph + \"\\n\\n\"\n",
    "\n",
    "        # Add the references section to the final report\n",
    "        final_report += \"\\n\\n### References\\n\"\n",
    "        for ref in references:\n",
    "            final_report += f\"{ref}\\n\\n\"\n",
    "\n",
    "        return final_report\n",
    "    except Exception as e:\n",
    "        return f\"Error generating report: {e}\"\n",
    "\n",
    "# Generate the report\n",
    "final_report = generate_report(client, top_k_documents)\n",
    "\n",
    "# Display the generated report\n",
    "print(final_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5fdf4ee-8c0e-4ca7-ae68-ac10840b3ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the key findings related to antibiotic resistance?\n",
      "Answer: 1. Antimicrobial resistance (AMR) in Neisseria gonorrhoeae is a serious global public health problem. Resistance to ceftriaxone, the last option for first-line empirical monotherapy of gonorrhoea, has been reported from many countries. In 2018, the first gonococcal isolates with ceftriaxone resistance plus high-level azithromycin resistance were identified in England and Australia.\n",
      "\n",
      "2. In most countries, resistance to ciprofloxacin is exceedingly high, azithromycin resistance is present and decreased susceptibility or resistance to ceftriaxone has emerged.\n",
      "\n",
      "3. For afebrile outpatients presenting with complicated cystitis, overall prevalence of resistance for trimethoprim-sulfamethoxazole, ciprofloxacin, nitrofurantoin, first-generation cephalosporin, and third-generation cephalosporin was 25.6%, 19.5%, 19.1%, 15.0%, and 6.9%, respectively.\n",
      "\n",
      "4. Resistance to ciprofloxacin in the rectal vaults of older northwestern Ohio males is significant but appears to be stable over the study period.\n",
      "\n",
      "5. In Ethiopia, close to 68% of gonococcal isolates were fluoroquinolone non-susceptible, with 60% resistant and 7% having an intermediate status. However, all tested\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.docstore.document import Document\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI embedding model\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "embedder = OpenAIEmbeddings(api_key=openai_api_key)\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "csv_path = 'abstracts_output.csv'  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Step 2: Prepare documents and metadata\n",
    "texts = df['text'].tolist()\n",
    "metadata = [{\"authors\": row['authors'], \"title\": row['title'], \"source\": row['source'], \"year\": row['year']} for _, row in df.iterrows()]\n",
    "\n",
    "# Convert each text and its metadata into a Document object\n",
    "documents = [Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadata)]\n",
    "\n",
    "# Step 3: Create the FAISS vector store from the documents and cache-backed embedder\n",
    "vector_store = FAISS.from_documents(documents, embedder)\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Function to answer open-ended questions using retrieved documents\n",
    "def answer_question(client, query):\n",
    "    # Retrieve the top 5 relevant documents\n",
    "    top_k_documents = vector_store.similarity_search(query, k=5)\n",
    "\n",
    "    # Combine the content of the retrieved documents for context\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in top_k_documents])\n",
    "\n",
    "    # Prepare the prompt for the open-ended question\n",
    "    open_ended_prompt = f\"Use the following context to answer the question:\\n\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "    # Use the OpenAI client to generate the answer based on the query and the context\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": open_ended_prompt}],\n",
    "        model=\"gpt-4\",  # You can use \"gpt-4\" or \"gpt-3.5-turbo\"\n",
    "        max_tokens=300,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    # Extract the answer from the response\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Example of using the function to answer a question\n",
    "question = \"What are the key findings related to antibiotic resistance?\"\n",
    "answer = answer_question(client, question)\n",
    "\n",
    "# Display the generated answer\n",
    "print(f\"Question: {question}\\nAnswer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450a1169-9780-472b-a98e-fea4b13974bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FDA Data:\\n  Antibiotic                 Brand Name               Generic Name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Indications and Usage                                                                                                                                          Side Effects\\nTetracycline Tetracycline Hydrochloride TETRACYCLINE HYDROCHLORIDE INDICATIONS AND USAGE To reduce the development of drug-resistant bacteria and maintain the effectiveness of tetracycline hydrochloride and other antibacterial drugs, tetracycline hydrochloride should be used only to treat infections that are proven or strongly suspected to be caused by susceptible bacteria. When culture and susceptibility information are available, they should be considered in selecting or modifying antibacterial therapy. In the absence of such data, local epidemiology and susceptibility patterns may contribute to the empiric selection of therapy. Tetracycline is indicated in the treatment of infections caused by susceptible strains of the designated organisms in the conditions listed below: Upper respiratory tract infections caused by Streptococcus pyogenes , Streptococcus pneumoniae and Hemophilus influenzae . Note: Tetracycline should not be used for streptococcal disease unless the organism has been demonstrated to be susceptible. Lower respiratory tract infections caused by Streptococcus pyogenes, Streptococcus pneumoniae, Mycoplasma pneumoniae (Eaton agent, and Klebsiella sp. ) Skin and soft tissue infections caused by Streptococcus pyogenes, Staphylococcus aureaus . (Tetracyclines are not the drugs of choice in the treatment of any type of staphylococcal infections.) Infections caused by rickettsia including Rocky Mountain spotted fever, typhus group infections, Q fever, rickettsialpox. Psittacosis caused by Chlamydophila psittaci. Infections caused by Chlamydia trachomatis such as uncomplicated urethral, endocervical or rectal infections, inclusion conjunctivitis, trachoma, and lymphogranuloma venereum. Granuloma inquinale caused by Klebsiella granulomatis . Relapsing fever caused by Borrelia sp . Bartonellosis caused by Bartonella bacilliformis . Chancroid caused by Hemophilus ducreyi. Tularemia caused by Francisella tularensis. Plaque caused by Yersinia pestis. Cholera caused by Vibrio cholerae. Brucellosis caused by Brucella species (tetracycline may be used in conjunction with an aminoglycoside). Infections due to Campylobacter fetus. As adjunctive therapy in intestinal amebiasis caused by Entamoeba histolytica . Urinary tract infections caused by susceptible strains of Escherichia coli, Klebsiella, etc. Other infections caused by susceptible gram-negative organisms such as E. coli, Enterobacter aerogenes, Shigella sp., Acinetobacter sp., Klebsiella sp., and Bacteroides sp. In severe acne, adjunctive therapy with tetracycline may be useful. When penicillin is contraindicated, tetracyclines are alternative drugs in the treatment of the following infections: Syphilis and yaws caused by Treponema pallidum and pertenue , respectively, Vincent's infection caused by Fusobacterium fusiforme, Infections caused by Neisseria gonorrhoeae, Anthrax caused by Bacillus anthracis, Infections due to Listeria monocytogenes, Actinomycosis caused by Actinomyces species, Infections due to Clostridium species. ['DRUG HYPERSENSITIVITY', 'NAUSEA', 'DRUG INEFFECTIVE', 'RASH', 'PAIN', 'VOMITING', 'OFF LABEL USE', 'HEADACHE', 'CHRONIC KIDNEY DISEASE', 'FATIGUE']\\n\\nWHO AWARE Data:\\n  Antibiotic         Class ATC code Category                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Explanation                                                                                                                                                               First choice Second Choice\\nTetracycline Tetracyclines  J01AA07   Access This group includes antibiotic classes that have higher resistance potential and includes most of the highest priority agents among the Critically Important Antimicrobials for Human Medicine1 and/or antibiotics that are at relatively high risk of selection of bacterial resistance. These medicines should be prioritized as key targets of stewardship programs and monitoring. Selected Watch group antibiotics are recommended as essential first or second choice empiric treatment options for a limited number of specific infectious syndromes and are listed as individual medicines on the WHO Model Lists of Essential Medicines. Bacterial infection of unspecified site, Neonatal conjunctivitis or dacryocystitis, Other specified conjunctivitis, Infectious keratitis, Trachoma, Infectious blepharitis           NaN\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.docstore.document import Document\n",
    "import random\n",
    "\n",
    "# Load the new CSV files\n",
    "fda_df = pd.read_csv('FDA.csv')\n",
    "aware_df = pd.read_csv('WHO_AWARE.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# List of antibiotics with formatting for FDA.csv where spaces are replaced with dots\n",
    "antibiotics = [\n",
    "    'Amikacin', 'Amoxycillin.clavulanate', 'Ampicillin', 'Azithromycin', 'Cefepime', \n",
    "    'Cefoxitin', 'Ceftazidime', 'Ceftriaxone', 'Clarithromycin', 'Clindamycin', \n",
    "    'Erythromycin', 'Imipenem', 'Levofloxacin', 'Linezolid', 'Meropenem', \n",
    "    'Metronidazole', 'Minocycline', 'Penicillin', 'Piperacillin.tazobactam', \n",
    "    'Tigecycline', 'Vancomycin', 'Ampicillin.sulbactam', 'Aztreonam', \n",
    "    'Aztreonam.avibactam', 'Cefixime', 'Ceftaroline', 'Ceftaroline.avibactam', \n",
    "    'Ceftazidime.avibactam', 'Ciprofloxacin', 'Colistin', 'Daptomycin', \n",
    "    'Doripenem', 'Ertapenem', 'Gatifloxacin', 'Gentamicin', 'Moxifloxacin', \n",
    "    'Oxacillin', 'Quinupristin.dalfopristin', 'Sulbactam', 'Teicoplanin', \n",
    "    'Tetracycline', 'Trimethoprim.sulfa', 'Ceftolozane.tazobactam', \n",
    "    'Cefoperazone.sulbactam', 'Meropenem.vaborbactam', 'Cefpodoxime', \n",
    "    'Ceftibuten', 'Ceftibuten.avibactam', 'Tebipenem'\n",
    "]\n",
    "\n",
    "# Randomly select an antibiotic from the list\n",
    "selected_antibiotic = random.choice(antibiotics)\n",
    "\n",
    "# Filter rows for the selected antibiotic from both FDA.csv and WHO_AWARE.csv\n",
    "selected_fda_df = fda_df[fda_df['Antibiotic'] == selected_antibiotic.replace(' ', '.')]\n",
    "selected_aware_df = aware_df[aware_df['Antibiotic'] == selected_antibiotic]\n",
    "\n",
    "# Combine rows from both datasets\n",
    "background_info = \"\"\n",
    "if not selected_fda_df.empty:\n",
    "    background_info += \"FDA Data:\\n\" + selected_fda_df.to_string(index=False) + \"\\n\\n\"\n",
    "if not selected_aware_df.empty:\n",
    "    background_info += \"WHO AWARE Data:\\n\" + selected_aware_df.to_string(index=False) + \"\\n\\n\"\n",
    "\n",
    "# Print out the background information for testing\n",
    "background_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3cc94a-19a2-4153-bccf-39e75dc53e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cecf4c4-90c7-4e2e-b7a4-9419018ffef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15299460-2089-45d3-9566-70fb8b96d01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\vivli_2024\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from openai import OpenAI\n",
    "import spacy\n",
    "\n",
    "# Load spaCy's English tokenizer\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI embedding model\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "embedder = OpenAIEmbeddings(api_key=openai_api_key)\n",
    "\n",
    "# Load the CSV files (FDA, WHO AWARE, and QA data)\n",
    "fda_df = pd.read_csv('FDA.csv')\n",
    "aware_df = pd.read_csv('WHO_AWARE.csv', encoding='ISO-8859-1')\n",
    "qa_df = pd.read_csv('antibiotics_qa.csv')\n",
    "\n",
    "# List of antibiotics\n",
    "antibiotics = [\n",
    "    'Amikacin', 'Amoxycillin.clavulanate', 'Ampicillin', 'Azithromycin', 'Cefepime', \n",
    "    'Cefoxitin', 'Ceftazidime', 'Ceftriaxone', 'Clarithromycin', 'Clindamycin', \n",
    "    'Erythromycin', 'Imipenem', 'Levofloxacin', 'Linezolid', 'Meropenem', \n",
    "    'Metronidazole', 'Minocycline', 'Penicillin', 'Piperacillin.tazobactam', \n",
    "    'Tigecycline', 'Vancomycin', 'Ampicillin.sulbactam', 'Aztreonam', \n",
    "    'Aztreonam.avibactam', 'Cefixime', 'Ceftaroline', 'Ceftaroline.avibactam', \n",
    "    'Ceftazidime.avibactam', 'Ciprofloxacin', 'Colistin', 'Daptomycin', \n",
    "    'Doripenem', 'Ertapenem', 'Gatifloxacin', 'Gentamicin', 'Moxifloxacin', \n",
    "    'Oxacillin', 'Quinupristin.dalfopristin', 'Sulbactam', 'Teicoplanin', \n",
    "    'Tetracycline', 'Trimethoprim.sulfa', 'Ceftolozane.tazobactam', \n",
    "    'Cefoperazone.sulbactam', 'Meropenem.vaborbactam', 'Cefpodoxime', \n",
    "    'Ceftibuten', 'Ceftibuten.avibactam', 'Tebipenem'\n",
    "]\n",
    "\n",
    "# Randomly select an antibiotic\n",
    "selected_antibiotic = antibiotics[0]  # For this example, we're just picking the first one\n",
    "\n",
    "# Filter rows for the selected antibiotic from both FDA.csv and WHO_AWARE.csv\n",
    "selected_fda_df = fda_df[fda_df['Antibiotic'] == selected_antibiotic.replace(' ', '.')]\n",
    "selected_aware_df = aware_df[aware_df['Antibiotic'] == selected_antibiotic]\n",
    "\n",
    "# Combine rows from both datasets to create background information\n",
    "background_info = \"\"\n",
    "if not selected_fda_df.empty:\n",
    "    background_info += \"FDA Data:\\n\" + selected_fda_df.to_string(index=False) + \"\\n\\n\"\n",
    "if not selected_aware_df.empty:\n",
    "    background_info += \"WHO AWARE Data:\\n\" + selected_aware_df.to_string(index=False) + \"\\n\\n\"\n",
    "\n",
    "# Load abstracts for FAISS vector store\n",
    "csv_path = 'abstracts_output.csv'  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(csv_path)\n",
    "texts = df['text'].tolist()\n",
    "metadata = [{\"authors\": row['authors'], \"title\": row['title'], \"source\": row['source'], \"year\": row['year']} for _, row in df.iterrows()]\n",
    "\n",
    "# Convert each text and its metadata into a Document object\n",
    "documents = [Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadata)]\n",
    "\n",
    "# Create the FAISS vector store from the documents\n",
    "vector_store = FAISS.from_documents(documents, embedder)\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(api_key=openai_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37186934-b7ec-4110-824b-5469a0819ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text using spaCy\n",
    "def spacy_tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "# Function to generate an answer using OpenAI\n",
    "def answer_question(client, question, background_info):\n",
    "    # Retrieve the top 3 relevant documents to reduce memory consumption\n",
    "    top_k_documents = vector_store.similarity_search(question, k=3)\n",
    "\n",
    "    # Combine the content of the retrieved documents for context\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in top_k_documents])\n",
    "\n",
    "    # Prepare the prompt for the question with background information\n",
    "    open_ended_prompt = f\"Use the following context and background information to answer the question:\\n\\n{context}\\n\\nBackground Information:\\n{background_info}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "\n",
    "    # Use the OpenAI client to generate the answer based on the question and context\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": open_ended_prompt}],\n",
    "        model=\"gpt-4\",  # You can use \"gpt-4\" or \"gpt-3.5-turbo\"\n",
    "        max_tokens=300,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    # Extract the generated answer\n",
    "    generated_answer = response.choices[0].message.content.strip()\n",
    "\n",
    "    return generated_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e3a15-5e84-4b77-a2e6-f9f0c0cc17e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one question from the QA dataset\n",
    "question_row = qa_df.iloc[0]  # For this example, we are selecting the first question\n",
    "\n",
    "question = question_row['Question']\n",
    "reference_answer = question_row['Answer']\n",
    "\n",
    "# Generate the answer using RAG\n",
    "generated_answer = answer_question(client, question, background_info)\n",
    "\n",
    "# Create a DataFrame to store the result\n",
    "result_df = pd.DataFrame([{\n",
    "    'Question': question,\n",
    "    'Reference Answer': reference_answer,\n",
    "    'Generated Answer': generated_answer\n",
    "}])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "output_csv = 'output_qa_with_one_answer.csv'\n",
    "result_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Saved the answer to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345c7aa-24a5-4415-a803-fa684bb0df59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874539e-60ab-4a69-aa62-87998d67fc48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
